# CS492 ML for NLP Fall 2019

## Teaching Staff

- Alice Oh, alice.oh@kaist.edu
- Dongkwan Kim, dongkwan.kim@kaist.ac.kr
- Changmin Lee, changmin.lee@kaist.ac.kr
- **When you send emails, please email to all TAs and prof. Oh.**

## Important Notes about Registering for this Course

- If you are lucky enough to be registered and selected for this class, PLEASE make sure you will not drop this class after it starts. If you are thinking of just "shopping around" to see what this course is like, please DROP IT NOW, so that students who really want to take this course can register. There were more than 90 students signed up for 40 slots, and dozens of students emailed me that they could not register because they have taken CS492 before. So please give up your seat if you are not serious about this course.
- If you have emailed me about not being able to register for this class because you have taken another CS492 before, you will be entered into a lottery and randomly picked (about 5 students) to be added into this class. You will receive email whether you have been selected this way by July 12. If you are selected, you must come to the first class to get your form signed.
- If you registered for this class but did not get selected, I cannot add you. There are too many students asking to be added. Hopefully some students will be dropping, so you can check frequently to see if there is an available slot.
- This course will be offered again in Fall 2020, probably as a regular course. At that time, we hope to be able to accommodate more students (current limit is 40). So please be patient if you really want to take this course.

## Course Description

This course will cover important problems and concepts in natural language processing and the machine learning models used in those problems.

## Prerequisites  

- You need to have good programming skills in Python.
- You need to have basic understanding of ML concepts. You do not need to have taken CS376 or any other undergraduate ML course, but you need to know concepts such as train vs test data, clustering vs classification, accuracy/precision/recall, overfitting, and basic classification models such as SVM, random forest, etc. You can learn these concepts as we go along, but you may find some lectures and papers difficult to understand if you do not put in extra time to learn these concepts.
- We will use [NumPy](https://numpy.org/)/[TensorFlow](https://tensorflow.org) in in-class exercises. You may start with little prior experience and learn these libraries during this semester, but that will require extra time and effort. Note that we do not provide any lectures about learning libraries.

## Materials
1. [Jacob Eisenstein, Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)
1. Recent papers from [ACL, EMNLP, NAACL, TACL, etc.](https://aclweb.org/anthology/)
1. (Optional Reference) [Jurafsky an Martin, Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf)

## Course Goals

By the end of the course, you will be able to

1. Understand important concepts in NLP
1. Read current research papers in NLP 
1. Implement some of the basic ML models for NLP
1. Conduct replication studies based on a recent NLP+ML paper
1. Communicate in written and spoken English about NLP+ML research

## Schedule (Subject to Change)

**Course Dates:** Tuesday, Sept 3 â€“ Thursday, Dec 19, 2019 

**Class Times:** Tuesday and Thursday at 13:00 - 14:15 

| Week |          Dates         |                 Topics                  |
|:-----:|:----------------------:|:---------------------------------------:|
|  1 |   Tue/Thurs Sept 3/5                         | Introduction / Math Review |
|  2 |   Tue/Thurs Sept 10/12                    | Word Vectors & Distributed Semantics / No Class on Sept 12 (Holiday) |
|  3 |   Tue/Thurs Sept 17/19                        | Word Vectors / Text Classification |
|  4 |   Tue/Thurs Sept 24/26                     | Text Classification |
|  5 |   Tue/Thurs Oct 1/3                      | Sequence Models / No Class on Oct 3 (Holiday)|
|  6 |   Tue/Thurs Oct 8/10                     | Project Proposals |
|  7 |   Tue/Thurs Oct 15/17                         | Language Models |
| 8 |   Tue/Thurs Oct 22/24                        | Midterm Exam |
| 9 |   Tue/Thurs Oct 29/31                          | Sequence Models |  
| 10 |   Tue/Thurs Nov 5/7                      | Machine Translation & Multilinguality |
| 11 |   Tue/Thurs Nov 12/14                     | Neural Language Models (ELMo, BERT, XLNet) |
| 12 |   Tue/Thurs Nov 19/21                     | NLP Applications (QA, Dialogue, Information Extraction, etc) |
| 13 |   Tue/Thurs Nov 26/28                     | Project Paper Presentations  |
| 14 |   Tue/Thurs Dec 3/5                     | Project Paper Presentations  |
| 15 |   Tue/Thurs Dec 10/12                     | Project Presentations  |
| 16 |   Tue/Thurs Dec 17/19                    | Project Report Due |


## Class Assignments

TBD 

### Team Projects

You will form teams of two, and as a team, pick one paper from ACL, EMNLP, NAACL, or TACL, published in 2016 to 2019, and replicate it. You will be required to change at least one thing -- dataset, model, or research question. More details will be given out during the first week of class.

## Evaluation
Your grade will be a combination of the following:

- Participation and attendance 10%
- Midterm exam 25%
- In-class exercises 15%
- Team Project 50% 
  - Proposal 5%
  - Paper presentation 10%
  - Final presentation 20%
  - Written report 10%
  - Teamwork 5%
